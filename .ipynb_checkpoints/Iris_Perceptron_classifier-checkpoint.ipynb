{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "disabled-noise",
   "metadata": {},
   "source": [
    "## Perceptron binary classification with Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Iris.csv and renaming the columns\n",
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "                 names = ['sepal_lenght','sepal_width','petal_lenght', 'petal_width', 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing dataset, getting rid of Iris-virginica label\n",
    "df = df[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting the two groups of data classified by variety:\n",
    "    # 'Iris-setosa': 'red'\n",
    "    # 'Iris-versicolor': 'green'\n",
    "plt.figure(figsize=(8,5))\n",
    "df.plot(kind='scatter', x='sepal_lenght', y='petal_lenght', \n",
    "        color=np.where(df['class']=='Iris-setosa','r', 'g'),\n",
    "        xlabel='Sepal lenght [cm]', ylabel='petal lenght [cm]', marker='x');\n",
    "\n",
    "fname =  \"initial_data\"\n",
    "plt.savefig(fname, dpi=75, transparent=False, format='jpg');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-calibration",
   "metadata": {},
   "source": [
    "## Developing a perceptron model which can classify flowers\n",
    "- We will be using 'sepal lenght' and 'petal lenght' as inputs\n",
    "- We will expect the right 'class' as output\n",
    "- The model activation function will be 'sigmoid(x)'\n",
    "- Outputs will be between 0 and 1, so we have to convert 'class' to this codification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining inputs\n",
    "X = np.array([df['sepal_lenght'], df['petal_lenght']]).T\n",
    "# Defining outputs. We will convert 'Iris-setosa' to 0 and 'Iris versicolor' to 1\n",
    "y = np.array([df['class']]).T\n",
    "y = np.where(y=='Iris-setosa',0,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-brother",
   "metadata": {},
   "source": [
    "### Perceptron:  \n",
    "&nbsp;\n",
    "<img src=\"perceptron.png\"\n",
    "     alt=\"Perceptron img\"\n",
    "     style=\"float: center; max-width: 60%;\" /> &nbsp;\n",
    "$$summation=(\\sum_{n=1}^{n} x_{n}*w_{n})+b$$\n",
    "$$activation= {\\sigma(summation)} = z$$\n",
    "$$error=y-z$$\n",
    "\n",
    "&nbsp;  \n",
    "&nbsp;\n",
    "    \n",
    "### Sigmoid function:  \n",
    "&nbsp;\n",
    "<img src=\"sigmoid.png\"\n",
    "     alt=\"Sigmoid img\"\n",
    "     style=\"float: center; max-width: 70%;\" />  &nbsp;\n",
    "<h4 style=\"text-align: center;\"> Backpropagation: </h4>\n",
    "$$confidence\\_inverse=\\sigma'(summation)$$\n",
    "$$weighted\\_error = error * confidence\\_inverse$$\n",
    "$$weights\\mathrel{+}=X*weighted\\_error*learning\\_rate$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def d_sigmoid(self,X):\n",
    "        return self.sigmoid(X) * (1 - self.sigmoid(X))\n",
    "    \n",
    "    def sigmoid(self,X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    \n",
    "    def predict(self,X):\n",
    "        self.summation = np.dot(X, self.weights) + self.bias\n",
    "        activation = self.sigmoid(self.summation)\n",
    "        return activation\n",
    "    \n",
    "    def train(self,X,y,n_iter=5,learn_rate=0.1):\n",
    "        # Defining weights and bias\n",
    "        size = np.shape(X)[1]\n",
    "        np.random.seed(111)\n",
    "        # Since our output are not between -1 and 1 and we dont want to stop\n",
    "        # the model to learn, we make an adjustment over it's weights\n",
    "        div = X.max() \n",
    "        self.weights = (np.random.rand(1,size).T * 2 - 1) / div\n",
    "        self.bias = (np.random.rand(1) * 2 - 1) / div\n",
    "        # Saving historic weights and bias && historic error\n",
    "        self.hist = np.concatenate((self.weights[:,0],self.bias),axis=0)\n",
    "        self.hist_error = []\n",
    "        # Model fitting\n",
    "        for _ in range(n_iter):\n",
    "            z = self.predict(X)\n",
    "            error = y - z\n",
    "            # Multipliying np.arrays like this: [a,b,c]*[d,e,f] = [a*d, b*e, c*f]\n",
    "            weighted_error = error * self.d_sigmoid(self.summation)\n",
    "            # Updating weights and bias\n",
    "            self.weights += np.array([np.mean(X * weighted_error, axis=0)]).T * learn_rate\n",
    "            self.bias += np.mean(weighted_error) * learn_rate\n",
    "            # Storing historic\n",
    "            new_data = np.concatenate((self.weights[:,0],self.bias),axis=0)\n",
    "            self.hist = np.vstack((self.hist,new_data))\n",
    "            self.hist_error.append(np.mean(error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model 100 times with a learning factor of 0.2\n",
    "perceptron = Perceptron()\n",
    "# Training\n",
    "iterations = 100\n",
    "learning_rate = 0.3\n",
    "perceptron.train(X,y,iterations,learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-minister",
   "metadata": {},
   "source": [
    "### Plotting weight and error evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = perceptron.hist\n",
    "error = perceptron.hist_error\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(len(data)), data[:,0], color='r', label='Weight 1')\n",
    "plt.plot(range(len(data)), data[:,1], color='g', label='Weight 2')\n",
    "plt.plot(range(len(data)), data[:,2], color='blue', label='Bias')\n",
    "plt.plot(range(1,len(error)+1), error, color='black', label='Error')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-moscow",
   "metadata": {},
   "source": [
    "### Visualizing desidion boundaries for two labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "    np.arange(x2_min, x2_max, resolution))\n",
    "    # Meshgrid() + ravel() is the equivalent of 2 for loop to cover a 2D grid \n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "    # plot class samples\n",
    "    # 2 times loop\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        matches = np.where(y==cl)\n",
    "        plt.scatter(x=X[matches[0], 0], y=X[matches[0], 1], alpha=0.8, c=colors[idx],\n",
    "            marker=markers[idx],label=np.where(cl==0,'Setosa','Versicolor'), edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "plot_decision_regions(X, y, classifier=perceptron, resolution=0.01)\n",
    "plt.xlabel('sepal length [cm]')\n",
    "plt.ylabel('petal length [cm]')\n",
    "plt.title('MODEL TRAINED '+ str(iterations) + ' TIMES')\n",
    "plt.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-hawaii",
   "metadata": {},
   "source": [
    "### Evolution of desition boundaries\n",
    "In a for loop that will run 'n' times we will do the following:  \n",
    "- We will train the model 'Iterator_n' times\n",
    "- We will save the output in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron2 = Perceptron()\n",
    "for i in range(100):\n",
    "    # Training perceptron 'i' times\n",
    "    perceptron2.train(X,y,i,0.1)\n",
    "    # Setting figure size\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    # Creating decision plot for the model\n",
    "    plot_decision_regions(X, y, classifier=perceptron2, resolution=0.01)\n",
    "    plt.xlabel('sepal length [cm]')\n",
    "    plt.ylabel('petal length [cm]')\n",
    "    plt.legend(loc='upper left')\n",
    "    fname =  'plot/' + \"{:03d}\".format(i)\n",
    "    plt.savefig(fname, dpi=75, transparent=False, format='jpg')\n",
    "    # Closing figure in order not to display it\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
